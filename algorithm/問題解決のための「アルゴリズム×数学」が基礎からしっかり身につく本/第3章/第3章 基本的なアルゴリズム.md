# 3.1 素数判定法

## 単純な素数判定法

- 2からN-1までを順に割り切れる数があるかどうかを検証する。
- 線形探索であり、計算量は`*O(N)*`
    - [線形時間](https://www.notion.so/19f93db055548095bb50cceeadd5d3e0?pvs=21)

## 高速な素数判定法

<aside>
💡

2からN-1までをすべて調べる必要はない。√N以下の整数まで調べてわりきれなければ素数と判定できる

</aside>

- 計算量は`O(√N)`

### 背理法を使って証明する

- 背理法とは
    - 事実Fが間違っていると仮定すると、矛盾が起こることを導く
        - Ex.  三角形の内角のうち少なくとも1つは60°以上である
            1. 事実が正しくない、すなわちすべての内角が60°未満と仮定する
            2. この場合、三角形の内角の和は(60°未満) + (60°未満) + (60°未満) = (180°未満)
            3. しかし、三角形の内角の和は必ず180°であるはずだ
            4. したがって「事実が正しくない」と言う仮定は矛盾を生じる
- [高速な素数判定法](https://www.notion.so/1b193db0555480299ab1fa4ce57a4c4e?pvs=21) の証明
    1. Nが合成数であり、1以外で最小のNの約数Aが√Nを超えていると仮定する
    2. 約数の性質により、`A × B = N`とnある正の整数Bが存在する。この時BはNの約数である
    3. しかし、`B = N / A < √N` である。これは2以上の最小の約数がAであることに矛盾する
    4. よって、仮定は成り立たず、この事実は正しい

### 応用例: 約数列挙

素数判定法と似たような次の手順でNの約数を列挙することができる。計算量は`O(√N)`

1.  i = 1,2,3, ..., [√N]について、Nがiで割り切れるかどうかを調べる
2. 割り切れる場合、iとN/iを約数に追加する

- 節末問題
    - 3.1.2 ❌
        - 自然数Nを素因数分解したときに、√Nを超えるものは一つしかない
        - 次のようなアルゴリズムで答えがわかる
            - Nを2で割れるだけ割る
            - Nを3で割れるだけ割る
            - 同じ操作を4,5,…[√N]についても行う
            - 最後に残ったNが1以外の場合、それを素因数に加える
        
        ```python
        N = int(input())
        
        # 素因数分解
        Answer = []
        LIMIT = int(N ** 0.5)
        for i in range(2, LIMIT + 1):
        	while N % i == 0:
        		N /= i
        		Answer.append(i)
        
        if N >= 2:
        	Answer.append(int(N))
        
        # 出力
        print(*Answer)
        ```
        
        - `N ** 0.5`
            
            [べき乗の拡張](https://www.notion.so/19b93db05554802c8671da4bcf134506?pvs=21) 公式2でルートはこの式で算出できる

# 3.2 ユークリッドの互助法
本説では、自然数AとBの最大公約数を求める問題を扱う

## 単純なアルゴリズム

- 33と88の最大公約数を求めるとする
    - 明らかに答えは33以下であるため、「1,2, …, 33」それぞれについて、33と88が割り切れるかどうかを調べる
    - 計算量は`*O(2min(A,B))*`となり、あまり効率的ではない

## ユークリッドの互助法

<aside>
💡

1. 大きいほうの数を「大きいほうを小さいほうで割った余り」に書き換えるという操作を繰り返す
2. 片方が0になったら操作を終了する。もう片方の数が最大公約数である
</aside>

- 計算量は`*O(log(A+B))*`
- イメージ
    
    ![IMG_4287.jpeg](attachment:06bc2f20-fa85-463c-81da-b7161f4550eb:IMG_4287.jpeg)
    

### 3個以上の最大公約数

- 3個以上の数の最大公約数も、ユークリッドの互除法によって計算することができる。
    - まず、1個目の数と2個目の数の最大公約数を計算する
    - 次に、前の計算結果と3個目の数の最大公約数を計算する
    - …
    - 最後に、前の計算結果とN個目の数の最大公約数を計算する

- 節末問題
    - 3.2.1
        
        
        | 3 | 4 | 5 | 6 |
        | --- | --- | --- | --- |
        | 104 | 14 | 14 | 0 |
        | 30 | 30 | 2 | 2 |

# 3.3 場合の数とアルゴリズム
## 基本方式

### ① 積の法則

- 組み合わせの数を掛け算によって求められること
- ex. 朝食
    - 明日の朝食は、おにぎり・食パン・サンドイッチのいずれか
    - 起床時間は5時, 6時, 7時, 8時のいずれか
    - 明日の朝食は3通り、起床時間は4通り。
    - 朝食と起床時間は3 × 4 = 12通り

### ② 積の法則の拡張

- 事柄が3つ以上の場合も組み合わせの数をかけることで求められる
- M通りの選択肢が考えられる事柄がN個あるような組み合わせの数は、
    - M × M × M × … M = Mᴺ 通り

### ③ n個のモノを並び替える方法の数は n! 通り

### ④ n個のモノからr個を並び替える方法は nPr 通り

- Ex. ABCDの中から2人を選び、並び順まで決める方法は₄P₂ = 4 × 3 = 12通り

### ⑤ n個のモノからr個を選ぶ方法はnCr通り

- nCr = n! / r!(n-r)!
- Ex. ABCDの中から2人を選ぶ方法
    - ₄C₂
        - =  4!  /  2!(4-2)!
        - = 4 × 3 × 2!  /   2! × 2!
        - = 4 × 3 / 2 × 1
        - = 6通り

## 応用例

- ① 買い物の方法の数
    - 問題
        
        ![image.png](attachment:747d1be8-4955-407e-b86f-916a5703f19f:image.png)
        
    - 商品の選び方を全探索する方法だと、*O(N²)*となり効率が悪い
    - 合計の値段が500円となるような買い物の仕方は以下の2通り
        1. 100の品物を1個、400円の品物を2個
        2. 200の品物を1個、300円の品物を2個
    - 100円=a, 200円=b, 300円=c, 400円=dとするとき、積の法則より以下で導き出せる
        - a通り × d通り + b通り × c通り
- ② 同色カードの組み合わせ
    - 問題
        
        ![image.png](attachment:80c24e26-804d-4673-8566-0c4bac6a70c4:image.png)
        
    - 全探索する方法だと、*O(N²)*となり効率が悪い
    - 赤色カードの枚数をxとする時、以下のことがわかる
        - 赤色のカードを2枚選ぶ方法は、xC₂ 通り
            - 黄色、青色も同じ
    - 赤色のカードの選ぶ方法 + 黄色のカードの選ぶ方法 + 青色のカードを選ぶ方法 で導き出せる
- ③ 全探索の計算回数
    - 問題
        
        ![image.png](attachment:854832ad-2786-4a6e-96e8-06da3a888b05:image.png)
        
    - 全探索する方法だと今回は5枚のカードを選ぶため、計算量は*O(N⁵)*である
    - N枚のカードを5枚選ぶ方法は、ɴC₅ 通りであるため、N=100の場合でも、選び方は
        
        ```
        (100 × 99 × 98 × 97 × 96) / 5 × 4 × 3 × 2 × 1 = 75287520通り
        ```
        
        → 10⁹を大幅に下回っており、5秒以内に実行が終わると予測可能。実際に制限時間内に計算は完了する。
        
    - 場合の数の公式は計算回数の見積もりにも利用できる場合がある

- 節末問題
    - 3.3.1
        
        ₂C₁ = 2 ⭕️
        
        ₈C₅ = 56 ⭕️
        
        ₇P₂ = 42 ⭕️
        
        ₁₀P₃ = 720 ⭕️
        
    - 3.3.2
        - 40通り ⭕️
    - 3.3.7
        - 128通り ❌   A. 3432通り
        - 解説
            
            ![image.png](attachment:92a26ba0-0f86-4706-816a-23749f36daed:image.png)
            
            **「上7回、右7回」の並べ方を数える必要がある**
            
            - 各移動が独立ではなく、合計14回の移動の中で「上を7回、右を7回」選ぶ必要があります。
            - これは「14個の移動のうち、7個を上方向に割り当てる組み合わせ」を求める問題です。

# 3.4 確率・期待値とアルゴリズム
## 確率

- N通りのパターンが同じ可能性で起こりうるとして、そのうちM通りについて事象Aが起こる時、事象Aが起こる確率をP(A)とする
    
    ```
    P(A) = M / N
    ```
    
- Ex. 一般的なサイコロを1回振り、3が出る確率
    - サイコロの目は6通り
    - そのうち3が出るのは1通り
        
        確率は 1/6
        

## 期待値

- 1回の試行で得られる平均的な値のことを期待値という
- 写真 p89 計算しき
- Ex. 確率0.1で賞金10000円、確率0.2で賞金1000円、確率0.7はハズレとなる賭け
    - 期待値　= (10000 × 0.1) + (1000 × 0.2) + 0 × 0.7 = 1200
    - 写真 p89

### 期待値の線形性

- 2つの試行を行い、1番目の試行の結果をX、2番目の試行の結果をYとします。そこでXの期待値をE[X]、Yの期待値をE[Y]とする時、X + Yの期待値はE[X] + E[Y]です。
- 3つ以上の試行を行ったときも同じことが言えます。N回の試行を行い、i番目の結果の期待値をX[i]とする時、すべての結果の合計の期待値はX[1] + X[2] + ・・・ + X[N]です
- p90 写真

## 応用例1: 2つのサイコロ

- 3.4.4 問題文 写真
- 単純な方法としては、青・赤の出目の和を調べた上で全部の平均を取ることが考えられる
    - → 非効率
- 期待値の線形性の法則を使い、青の出目の期待値と赤の出目の期待値をたす
    - 青の出目の期待値 (10 + 20 + 30 + 40 + 50 + 60) ÷ 6 = 35
    - 赤の出目の期待値 (0 + 1 + 3 + 5 + 6 + 9) ÷ 6 = 4
    - 2つのサイコロの和の期待値は 35 + 4 = 39となる

## 応用例3: 選択式問題の試験でランダムに答える

![image.png](attachment:dc8cfe6c-f24b-47ef-8506-4b4bd8df74f9:image.png)

- どの問題に正解してどの問題を間違えたかの組み合わせを全探索する方法は2ᴺ通りで非効率
- 選択肢がx個の問題を正解する確率は`1 / x` であるため、期待値の線形性の法則を使うと下記のようにして求められる
    
    ```
    Q₁/ P₁ + Q₂ / P₂ + ・・・ + Qɴ / Pɴ
    ```
    
    → 計算量O(N)で求められる
    
- p92 画像

- 節末問題
    - 3.4.1 ⭕️
        - 2個目のサイコロの数が1個目のサイコロの数未満であるときの組み合わせの数が抜けているため
    - 3.4.2 ⭕️
        - 期待値 370円
        - 500円の時は損である
    - 3.4.3  ⭕️
        - コード
    - 3.4.4 ❌
        - 解答
            
            ![image.png](attachment:bcaef81a-b972-48e4-aca2-fb63ea41388b:image.png)
            
            ![image.png](attachment:4f15b5d6-992c-41d3-8944-53d2e0b45270:image.png)
            
            [cが1未満の正の数の時、1 + c + c² + c³ + … の値は 1 / 1- cとなる ](https://www.notion.so/c-1-1-c-c-c-1-1-c-1af93db05554802f8a45eea2834c4851?pvs=21) 
            
            ![image.png](attachment:8d1be75d-8e4e-46f5-a5df-99371aabd83a:image.png)

# 3.5 モンテカルロ法
## 導入: コインを投げてみよう！

コインを10回投げてみて、何個表が出るか。

- 期待値は5個だが、実際の確率分布を見てみるとばらつきが大きいことがわかる
- 投げる回数を100回、1000回投げてみるとばらつき度合いが小さくなり大半が40~60個表が出る結果となる
    
    ![IMG_4350.jpeg](attachment:d4086e3b-26bb-4dbc-bcbc-1c367abbd00e:IMG_4350.jpeg)
    
    - → 表が出る確率pの分からないコインでも、投げる回数を増やせば、pの値をより正確に推測できることを意味する

## モンテカルロ法

- 乱数を用いたアルゴリズムの一種。
- 一例として以下の手法がよく使われる
    
    <aside>
    💡
    
    ある物事の成功率を推測する際に、*n*回のランダムな試行を行う。そのうち*m*回成功した場合、理論上の成功率が m / nであるとみなして近似する。例えば、コインを10回投げて6回表が出た場合、「表が出る確率はおおよそ60%である」とみなす
    
    </aside>
    
    → 試行回数 n を増やせば増やすほど精度が良くなる
    

### 応用例: 円周率πの計算

- モンテカルロ法の応用例の一つとして円周率πの近似値を計算する方法
    1. 一辺が1cmの正方形の中に、n個の点をランダムな位置に打つ
    2. 左下角を中心とする半径1cmの円内に入った点の個数をmとする
    3. そこで、4m / nを円周率πの近似値とする
    
    ![IMG_4351.jpeg](attachment:8f7b6a0b-c1da-49bc-a761-302683135bc9:IMG_4351.jpeg)
    
- この方法でうまくいく理由は、正方形の中で半径1cmの円に入る部分の面積がπ/4であること、すなわち青色領域内に点を打つ確率が π/4であることから説明できる

## モンテカルロ法の理論的検証

### 前提: 平均と標準偏差

- データや確率分布のおおまかな特徴を表す数値として、以下の2つが有名
    - 平均値 μ(ミュー): データの平均的な値
    - 標準偏差 σ(シグマ): データの散らばり具合
- N個のデータx1, x2, ・・・, xNにおける平均値と標準偏差は以下の式で定義される
    
    ![IMG_4352.jpeg](attachment:00eb51d9-11fc-4b4d-a5e2-7a5f367ab4b8:IMG_4352.jpeg)
    
- 具体例
    
    ![IMG_4353.jpeg](attachment:f7872d7b-de03-41d9-9aa4-c75219e4169b:IMG_4353.jpeg)
    

### 前提: 正規分布

- p98図
- 正規分布には68-95-99.7則と呼ばれる次の重要な性質がある
    - μ - σ以上μ + σ以下の範囲に全体の約68%が含まれる
    - μ - 2σ以上μ + 2σ以下の範囲に全体の約95%が含まれる
    - μ - 3σ以上μ + 3σ以下の範囲に全体の約99.7%が含まれる
- Ex.
    - p99図

## 検証

- p99 性質 写真
- [](https://www.notion.so/1ba93db055548073b86ecae95df29f3a?pvs=21) で述べたアルゴリズムで、半径1の円内に入る確率は p = π/4であるため、試行回数nが1万回の時、円内に打った点の割合は以下の正規分布に従う
    - 平均: μ = π/4 ≒ 0.7854
    - 標準偏差: σ =  ≒ 0.0041
- 68-95-99.7則により、」1万個のうち円内に打たれたものの割合は
    - 0.7731(0.7854 - 3 × 0.0041)以上0.7977(0.7854 + 3 × 0.0041)となる確率は99.7%
- 求める円周率の近似値は「割合に4を掛けた値」であるため、以下のようになる
    - 0.7731 × 4 = 3.0924以上
    - 0.7977 × 4 = 3.1908以下
- 以上よりモンテカルロ法では、1万回の試行で円周率をわずか0.05程度の誤差で計算することが可能と言える
    - p100 イメージ図

- 節末問題
    - 3.5.1
        1. 平均 0.5 ⭕️
            - 標準偏差 ❌ 0.005
                - √0.000025の求め方
                    
                    ![image.png](attachment:014e7bdb-7e8f-4b67-b495-b45b786dea80:image.png)
                    
                    [4つの指数法則が成り立つ。](https://www.notion.so/4-19b93db0555480df8f2bf1be38aaab8d?pvs=21) 
                    
            - 回数に換算すると
                - 平均 0.5 × 10000 = 5000回
                - 標準偏差 0.005 × 10000 = 50回
        2. ❌ 
            - 95%
        3. ❌ 
            - 50% ではない可能性が高い
                - 平均と標準偏差を使用した正規分布を使用して、99.7 %の割合で表が出る回数の範囲は [μ - 3σ以上μ + 3σ以下の範囲に全体の約99.7%が含まれる](https://www.notion.so/3-3-99-7-1ba93db055548098958bf99c458ba362?pvs=21) より、4850 ~ 5150の範囲であるため、5800という数値は50%とはいえない可能性が高いと言える
- 3.5.2
    1. ❌
        - 解説
            
            ![image.png](attachment:fb9a0bd5-ac12-4114-9cd8-460fa220e717:image.png)
            
            - ランダムに点を打ち、座標(3,3)に対して距離が3以下か、座標(3,7)に対して距離が2以下かを求めれば良い
            
            ```python
            import random
            
            N = 1000000 # N は試行回数（適宜変更する）
            M = 0
            for i in range(N):
            	px = 6.0 * random.random()
            	py = 9.0 * random.random()
            	
            	# 点 (3, 3) との距離。この値が 3 以下であれば半径 3 の円に含まれる。
            	dist_33 = ((px - 3.0) ** 2 + (py - 3.0) ** 2) ** 0.5
            	
            	# 点 (3, 7) との距離。この値が 2 以下であれば半径 2 の円に含まれる。
            	dist_37 = ((px - 3.0) ** 2 + (py - 7.0) ** 2) ** 0.5
            	
            	# 判定
            	if (dist_33 <= 3.0 or dist_37 <= 2.0):
            		M += 1
            
            print(M)
            ```
            
    2. ❌
        - 長方形の面積は6 × 9 = 54
        - 1の結果からモンテカルロの法則で確率を算出し、面積に対し確率をかければ答えを導き出せる
            - 1にて100万回の試行のうち、円内に含まれている個数が719653だとすると、
            - 54 × 716953 ÷ 1000000 = 38.861262

# 3.6 ソートと再帰の考え方
## ソートとは

- 複数のデータを決められた順序で整列する操作のこと

## 選択ソート

- まだ調べていない中で最も小さい数を探すことを繰り返して、配列をソートする手法のこと
- アルゴリズムの手順は以下の通り
    
    <aside>
    💡
    
    次の操作をN-1回繰り返す。i回目の操作では、以下のことを行う。
    1.未ソート部分（AiからAɴまで）の中で最小の要素A*min*を探す
    2.AiとA*min*を交換する
    このとき、操作後のA₁, A₂, .. Aɴは小さい順に整列されている。
    
    </aside>
    
    - p102 手順
    - p102 イメージ
- 計算量
    - N個の数の中から最小値を見つけるにはN **- 1回の比較を行う。2回目以降もN -2回、N-3回、…、2回、1回と続く。
    - 1からNまでの総和はN(N+1) / 2となるため、計算量はO(N²)だと言える
        - Nが1万程度であれば高速に動作するが、さらに大きくなると時間がかかる

## 再帰とは

- アルゴリズムなどを記述する際に、自分自身を引用する形で定義することを再帰的定義という
- 自分自身を呼び出す関数のことを再帰関数という
- 再帰関数の例① 階乗
    
    ```python
    N = int(input())
    def func(N):
      if N == 1:
          return 1
      return func(N-1)*N
    
    print(func(N))
    ```
    
    - 関数func(N)の値の計算のために同じ関数func(N - 1)を呼び出しているため
- 再帰関数の例② ユークリッドの互助法
    
    ```python
    def GCD(A, B):
      if B == 0: return A
    
      return GCD(B, A % B)
    ```
    
    - イメージ p107
- 再帰関数の例③ 分割統治法で合計値を求める
    
    ```python
    def solve(l: int, r: int) -> int:
      if r - l == 1:
        return A[l]
    
      m = (l + r) // 2
      s1 = solve(l, m)
      s2 = solve(m, r)
      return s1 + s2
    
    print(solve(0, N))
    ```
    

## マージソート

### Merge操作

```
長さaの列Aと長さbの列Bが与えられます。ここで列A・Bはすでにソートされています。
2つの列を合併し、小さい順に整列するプログラムを作成してください。
```

- 以下のアルゴリズムを使用する
    
    <aside>
    💡
    
    1. 列Cを用意する。列Cは最初、空である。
    2. 以下の操作を、列A・列Bのすべての要素が消えるまで繰り返す.。
        1. 列Aが空であれば、列Bで最小の要素を列Cに移す
        2. 列Bが空であれば、列Aで最小の要素を列Cに移す
        3. そのいずれでもなければ、列Aで残っている最小の要素と、列Bで残っている最小の要素を比較する。その後、小さいほうを列Cに移す
    </aside>
    
- p110 イメージ

### マージソートの手順

<aside>
💡

- k個の要素からなる列を、それぞれk/2個の要素からなる列A・列Bに分割する
- 列Aに対してマージソートを行い、ソートした後の列をA’とする
- 列Bに対してマージソートを行い、ソートした後の列をB’とする
- 列A’とB’に対してMerge操作を行うことで、k個の要素からなる列がソートされる
- 最初は、個の数A₁, A₂, .. Aɴに対してマージソートを行う
</aside>

- p111 イメージ

### マージソートの計算量

- O(N log N)回

## そのほかのソートアルゴリズム

### 挿入ソート

- 配列を部分的にソートしながら要素を適切な位置に挿入していくシンプルなソートアルゴリズム
- 平均的なケース・最悪なケースでは計算量はO(N²)であり、、効率的ではない
- アルゴリズム
    1. **配列の2番目の要素から開始**（1番目の要素はすでにソート済みと考える）。
    2. **現在の要素を前のソート済み部分と比較し、適切な位置に挿入**する。
    3. **この操作を配列の最後の要素まで繰り返す**

### クイックソート

- 配列を小さい値と大きい値に分割しながらソートする「分割統治法」**に**基づく高速なソートアルゴリズム
- 平均計算量はO(N log N)であり、効率的
- アルゴリズム
    1. **基準値（ピボット）を選ぶ**
        - 一般的には配列の先頭・末尾・中央値・ランダムな要素などをピボットにする。
    2. **ピボットより小さい要素と大きい要素で分割**
        - 配列を **「ピボットより小さいグループ」＋「ピボット」＋「ピボットより大きいグループ」** に分ける。
    3. **それぞれのグループに対して再帰的にクイックソートを適用**
        - 小さいグループ・大きいグループを再帰的にソートすることで、最終的にソートされた配列が得られる。
    - 擬似コード
        
        ```
        QuickSort(配列):
            もし 配列の要素数 <= 1 なら 終了  (すでにソート済み)
        
            ピボット = 配列の適当な要素
            小さいグループ = [ピボットより小さい要素]
            大きいグループ = [ピボットより大きい要素]
        
            小さいグループを QuickSort する
            大きいグループを QuickSort する
        
            return [小さいグループ] + [ピボット] + [大きいグループ]
        
        ```
        

### 計数ソート

- **整数**のデータに対して**線形時間 O(n+k)**で動作する高速なソートアルゴリズム。**要素の出現回数を数えて直接並び替える**方法をとる
- アルゴリズム
    1. **データの最大値・最小値を取得**（データの範囲を決定）
    2. **カウント配列（頻度配列）を作成**し、各要素の出現回数を記録
    3. **カウント配列を累積和に変換**し、各要素の最終的な配置位置を決定
    4. **元の配列をスキャンして新しい配列に要素を配置**
    5. **ソート済みの配列を返す**
    - 擬似コード
        
        ```
        CountingSort(配列):
            1. 最大値 k を見つける
            2. 長さ (k+1) のカウント配列 count[] を作成し、すべて 0 に初期化
            3. 元の配列をスキャンし、各要素の出現回数を count[] に記録
            4. count[] を累積和に変換し、各要素の最終位置を決定
            5. 元の配列を逆順にスキャンし、新しい配列 output[] に要素を配置
            6. output[] を返す
        ```
        
    - 平均計算量・最悪計算量はO(n+k)

- 節末問題
    - 3.6.1 ⭕️
        1. 1
        2. 2
        3. 3
        4. 5
    - 3.6.2
        - パス

# 3.7 動的計画法 ~ 漸化式の利用 ~
- 数列の漸化式とは
    
    数列において、前の項の結果からその項の値を求める規則のことを漸化式(ぜんかしき)と呼ぶ
    
    [項](https://www.notion.so/19b93db055548066bbc0d154ecbf1f50?pvs=21) 
    
    - 漸化式の例①: 等差数列
        - 漸化式を満たす数列を求める一番簡単な方法は、前の項から順番に一つずつ計算していくこと
        - p115 例
            - 直前の項の結果からその項の値を求められるようになっている
            - an を nの式で表したものを数列の一般項と呼ぶ
        - p115 イメージ
    - 漸化式の例②: フィボナッチ数列
        - 直前の項の結果からのみならず、2つ以上前の項の結果を利用することもある
        - p116 文字列
        - p116 イメージ
    
- 動的計画法
    - 数列の漸化式のように、小さい問題の結果を利用して解くアルゴリズムのこと
    -