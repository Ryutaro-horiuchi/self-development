## はじめに

- キーバリューストア
    - 各々固有の識別子をキーとしてキーに関連づけられた値を格納する
    - キー
        - 一意である
        - プレーンテキストでもハッシュ化された値でも可能だが、パフォーマンス上の理由から短いキーが効果的
    - 値
        - 文字列、リスト、オブジェクトが使用可能

## 単一サーバーのキーバリューストア

- 1台のサーバーに置かれたキーバリューストアの開発は簡単ではあるが、容量的な制約から、全てをメモリに格納することは困難
    - 2つの最適化が可能
        - データ圧縮
        - 使用頻度の高いデータのみをメモリに保存し、残りはディスクに保存する

## 分散型キーバリューストア

- キーバリューペアを多数のサーバーに分散して配置する
- 分散システムを設計する場合、CAP定理の理解が重要になる

### CAP定理

一貫性、可用性、分割耐性からなり、同時に保証するのは不可能であるとされている

- 一貫性
    - どのノードに接続しても、すべてのクライアントが同じデータを同時に見られる
- 可用性
    - 一部のノードがダウンしても、レスポンスを得られる
- 分断耐性
    - 2つのノードで通信が途絶えていても(ネットワークの分断)、システムが動作し続けること
- 2つのCAP特性によって分類
    
    ![IMG_6920.jpeg](attachment:5423848b-7a04-48f3-b114-f1d79953fd89:IMG_6920.jpeg)
    

### 実世界の分散システム

- ネットワークの分断が発生した場合、一貫性と可用性のどちらかを選択しなければならない
- Ex. 図6-3 n3がダウン
    
    ![IMG_6921.jpeg](attachment:3702a9da-ee29-4da3-a14c-61d02a188739:IMG_6921.jpeg)
    
    - n1, n2にデータが書き込まれた場合はn3にはデータが伝搬しない(逆も然り)
    - 可用性より一貫性を選ぶ(CPシステム)
        - これら3つのサーバー間でのデータの不整合を避けるために、n1とn2の書き込み操作をすべてブロックする必要がある → システムが利用できなくなる
    - 一貫性より可用性を選ぶ(APシステム)
        - システムは古いデータを返す必要があるが、読み込みを受け付ける
        - n1とn2は書き込みを受け続け、ネットワークの分断が解除された時点でn3にデータが同期される

## システム構成要素

キーバリューストアを構築するために使用するコアとなる構成要素とテクニックの説明。Dynamo, Casssandra, BigTableに基づいている

### データの分割

- 大規模なアプリケーションの場合、データを小さなパーティションに分割し、複数のサーバーに格納する
    - 課題
        - 複数のサーバーにデータを均等に分散させること
        - ノードの追加や削除に伴うデータの移動を最小限に抑えること
- [5章 コンシステントハッシュの設計](https://www.notion.so/5-24793db05554804384ebe0a92c77ab04?pvs=21) では、課題を解決する優れたアプローチ

### データの複製

- 高い可用性と信頼性を実現するために、N台のサーバーに非同期で複製する必要がある
- キーがハッシュリング上のある位置にマップされた後、その位置から時計回りに進み、リング上にあるN個のサーバーを選んで複製データを保存する
    - イメージ
        
        ![IMG_6922.jpeg](attachment:b99ef724-8c00-42ca-88c8-5ecd7d97d199:IMG_6922.jpeg)
        

### 一貫性

- データは複数のノードに複製されるため、複製データ間を同期する必要がある
- クォーラムコンセンサスは読み込みと書き込みの両方において一貫性を保証する
    - 定義
        - **W（Write Quorum）**: 書き込み操作を承認するために必要なノードの数
        - **R（Read Quorum）**: 読み取り操作を承認するために必要なノードの数
        - **N**: レプリカの総数
    - イメージ
        
        ![IMG_6925.jpeg](attachment:62e587f3-2d8b-47d8-9622-68a9cc42e1b6:IMG_6925.jpeg)
        
    - 説明
        - W = 1は、イメージの構成では*s0, s1, s2*でデータが複製されるが、W = 1は、コーディネーターが少なくとも一つの確認レスポンスを受信しなければ、書き込み操作が見なされないことを意味する。
        - `W + R > N` の時、必ず**読み取りと書き込みの集合が重なるノードが存在**するため、整合性が保証されます。
            - Ex. N=3, W=2, R=2
                - 書き込みで A, B が更新済み、C は古い
                - その後読み取りで 2台選ぶ
                - (A, B) → 最新
                - (A, C) → A が最新を持っている
                - (B, C) → B が最新を持っている
                - → **どの組み合わせでも最新ノードに必ず当たるため、**クライアントは矛盾があっても「最新を特定できる」仕組みになっている
    - トレードオフ
        
        <aside>
        💡
        
        W, R, Nはレイテンシーと一貫性との典型的なトレードオフ
        
        </aside>
        
        - `R = 1, W = N`の場合: システムは高速読み出しに最適化されている
        - `W= 1, R = N`の場合: システムは高速書き込みに最適化されている
        - `W + R > N` の場合：強い一貫性が保証される
        - `W + R ≤ N` の場合：強い一貫性は保証されない

**一貫性モデル**

- データの一貫性の程度を定義するものであり、幅広い一貫性モデルが存在する
- 強い一貫性
    - クライアントがデータを書き込むと、その直後に行われる全ての読み取りは **必ず最新の値を返す**。
        - → データの鮮度が常に保証される
- 弱い一貫性
    - 書き込み直後に読み取りを行っても、**必ずしも最新の値が返るとは限らない**。
        - → 読み取りが速く、可用性は高い
- 最終的な一貫性
    - 弱い一貫性の一種で、時間が経てば **最終的には全ノードが同じ値に収束する**ことを保証するモデル。
        - → 大規模な分散システム（特に可用性優先のシステム）で広く利用される

### 不具合の解消: バージョン管理

- レプリケーションにより、複製データ間で不整合が生じることがある。この不整合を解消する上で使用されるのが、バージョン管理とベクターロックである
- ベクターロック
    - データに関連づけられた[サーバー, バージョン]のペア。バージョンが先行するか、後続するか、互いに不整合かをチェックするために使用される
        - Ex. `*D([S1, v1], [s2, v2], …[sn, vn])*`
            
            Dはデータ。S1はサーバー番号、v1はバージョンカウンタ
            
    - データがSiに書き込まれた場合、サーバーは以下のタスクのいずれかを実行する。
        - [Si, vi]が存在する場合は、viをインクリメントする
        - そうでなければ、新しい[si, 1]を作成する
        - イメージ図
            
            ![IMG_6923.jpeg](attachment:37074e34-6495-4aa6-9e69-d182d9a8737c:IMG_6923.jpeg)
            

### 障害対応

**障害を検出するための技術**

- ゴシッププロトコル
    - 分散システム内のノード同士が、ランダムに選んだ別のノードと定期的に情報を交換する仕組み。人間社会の「うわさ話（ゴシップ）」のように、徐々に全体に広まっていく。
    - 障害対応時の流れ
        1. 障害検知
            - 各ノードは「ハートビート」や「シーケンス番号」を持つ
                - 各ノード自身が定期的にハートビートカウンタを増加
            - 他ノードとゴシップする際に最新の値を比較し、一定時間応答がなければ「suspect（疑わしい）」と判定。
            - さらに一定時間が経過し、他のノードからも確認されれば「dead（死亡）」と確定。
        2. 障害情報の伝播
            - 「ノードXがダウンした」という情報がゴシップで全体に拡散。
            - 拡散は指数関数的に広がるため、数秒〜数十秒でクラスタ全体に共有される。
        - イメージ
            
            ![IMG_6924.jpeg](attachment:5cc3f0ca-ce75-4127-8450-738b89013088:IMG_6924.jpeg)